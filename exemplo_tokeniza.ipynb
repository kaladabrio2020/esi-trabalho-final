{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd9cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário (palavra -> índice):\n",
      "{'<OOV>': 1, 'banana': 2, 'maçã': 3, 'e': 4, 'gosto': 5, 'de': 6, 'é': 7, 'muito': 8, 'boa': 9, 'são': 10, 'frutas': 11}\n",
      "\n",
      "Frequência de cada palavra:\n",
      "gosto: 1\n",
      "de: 1\n",
      "maçã: 2\n",
      "e: 2\n",
      "banana: 3\n",
      "é: 1\n",
      "muito: 1\n",
      "boa: 1\n",
      "são: 1\n",
      "frutas: 1\n",
      "\n",
      "Textos transformados em sequência de tokens:\n",
      "[[5, 6, 3, 4, 2], [2, 7, 8, 9], [3, 4, 2, 10, 11]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Exemplo de DataFrame com uma coluna de texto\n",
    "df = pd.DataFrame({\n",
    "    'texto': [\n",
    "        \"gosto de maçã e banana\",\n",
    "        \"banana é muito boa\",\n",
    "        \"maçã e banana são frutas\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Instanciando o tokenizador\n",
    "tokenizer = Tokenizer(lower=True, split=' ', oov_token=\"<OOV>\")  # lower=True para tudo minúsculo\n",
    "tokenizer.fit_on_texts(df['texto'])  # treina o tokenizador no texto\n",
    "\n",
    "# Transforma os textos em sequências de inteiros\n",
    "sequences = tokenizer.texts_to_sequences(df['texto'])\n",
    "\n",
    "# Vocabulário\n",
    "vocabulario = tokenizer.word_index\n",
    "\n",
    "# Frequência das palavras\n",
    "frequencias = tokenizer.word_counts  # OrderedDict\n",
    "\n",
    "# Resultados\n",
    "print(\"Vocabulário (palavra -> índice):\")\n",
    "print(vocabulario)\n",
    "\n",
    "print(\"\\nFrequência de cada palavra:\")\n",
    "for palavra, freq in frequencias.items():\n",
    "    print(f\"{palavra}: {freq}\")\n",
    "\n",
    "print(\"\\nTextos transformados em sequência de tokens:\")\n",
    "print(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3f17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(output_mode='int')\n",
    "vectorizer.adapt(df['texto'].values)\n",
    "\n",
    "tokens = vectorizer(df['texto'].values)\n",
    "\n",
    "# Para ver o vocabulário:\n",
    "vocab = vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f70f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int64, numpy=\n",
       "array([[ 8, 10,  3,  4,  2],\n",
       "       [ 2,  5,  7, 11,  0],\n",
       "       [ 3,  4,  2,  6,  9]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
